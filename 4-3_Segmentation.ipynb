{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import os\n",
    "\n",
    "# proxyの設定．\n",
    "# keras.datasetsでは，datasetを直接ダウンロードするので，学内マシンからは通常必要．\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.uec.ac.jp:8080/\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.uec.ac.jp:8080/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"      # \"0\":GPU0, \"1\":GPU1, \"0,1\":GPUを2つとも使用\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage import feature,filters\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "# ResNet50 による 1000種類分類\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1206624\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 27 18:13 resnet50-19c8e357.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB   4966400 Apr 29 20:54 squeezenet1_1-f364aa15.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 25 19:43 vgg16-397923af.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 574673361 Apr 29 13:53 vgg19-dcbb9e9d.pth\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/milesial/Pytorch-UNet/archive/master.zip\" to /home/yanai-lab/yamamoto-k/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load('milesial/Pytorch-UNet', 'unet_carvana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 Pytorch-UNet/predict.py -i carvana_1.jpeg -o output.jpg -m unet_carvana_scale1_epoch5.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![carvana_1](carvana_1.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![carvana_1](output.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained model を探すためにネットの海を探し回っていた。結果的にUNetのpretrained modelを用いいたが、epoch数は少ない。それっぽいマスクはできている。\n",
    "U-netはエンコーダーでデータを圧縮していって、圧縮したデータをデコーダーで展開させる時にエンコーダの特徴量を埋め込むことで、行っている。\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "        \n",
    " 構造が単純でなのはFCNで全結合層をConvolution層に置き換えるだけであったので、構造を真似すれば構成できる。\n",
    " \n",
    "それぞれで、領域分割が何を目的として作られているかで、性質が変わりそうなので、そういった背景も考慮しながらモデルを選ぶのもいいかもしれない。\n",
    "\n",
    "\n",
    "https://github.com/meetshah1995/pytorch-semseg<br>\n",
    "https://github.com/zijundeng/pytorch-semantic-segmentation<br>\n",
    "https://github.com/delta-onera/segnet_pytorch<br>\n",
    "\n",
    "https://pytorch.org/hub/pytorch_vision_fcn_resnet101/\n",
    "\n",
    "https://github.com/milesial/Pytorch-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
